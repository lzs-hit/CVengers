#include <torch/torch.h>
#include <torch/script.h>
#include <opencv2/opencv.hpp>
#include <iostream>
#include <vector>
#include <string>
#include <filesystem>

// å®šä¹‰CNNæ¨¡å‹ç»“æ„
struct SimpleDigitCNNImpl : torch::nn::Module {
    SimpleDigitCNNImpl() :
        conv1(register_module("conv1", torch::nn::Conv2d(torch::nn::Conv2dOptions(1, 32, 3).padding(1)))),
        conv2(register_module("conv2", torch::nn::Conv2d(torch::nn::Conv2dOptions(32, 64, 3).padding(1)))),
        conv3(register_module("conv3", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 128, 3).padding(1)))),
        fc1(register_module("fc1", torch::nn::Linear(128 * 16 * 16, 256))),
        fc2(register_module("fc2", torch::nn::Linear(256, 10))),
        dropout1(register_module("dropout1", torch::nn::Dropout(0.25))),
        dropout2(register_module("dropout2", torch::nn::Dropout(0.25))),
        dropout3(register_module("dropout3", torch::nn::Dropout(0.25))),
        dropout4(register_module("dropout4", torch::nn::Dropout(0.5)))
    {}

    torch::Tensor forward(torch::Tensor x) {
        // ç¬¬ä¸€å±‚å·ç§¯å—
        x = torch::relu(conv1(x));
        x = torch::max_pool2d(x, 2);
        x = dropout1(x);

        // ç¬¬äºŒå±‚å·ç§¯å—
        x = torch::relu(conv2(x));
        x = torch::max_pool2d(x, 2);
        x = dropout2(x);

        // ç¬¬ä¸‰å±‚å·ç§¯å—
        x = torch::relu(conv3(x));
        x = torch::max_pool2d(x, 2);
        x = dropout3(x);

        // å…¨è¿æ¥å±‚
        x = x.view({x.size(0), -1});
        x = torch::relu(fc1(x));
        x = dropout4(x);
        x = fc2(x);

        return x;
    }

    torch::nn::Conv2d conv1, conv2, conv3;
    torch::nn::Linear fc1, fc2;
    torch::nn::Dropout dropout1, dropout2, dropout3, dropout4;
};
TORCH_MODULE(SimpleDigitCNN);

// è‡ªå®šä¹‰æ•°æ®é›†ç±»
class DigitDataset : public torch::data::Dataset<DigitDataset> {
public:
    DigitDataset(const std::string& data_dir, bool is_train = true) {
        std::string phase_dir = is_train ? (data_dir + "/train") : (data_dir + "/test");
        
        // æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if (!std::filesystem::exists(phase_dir)) {
            std::cerr << "é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: " << phase_dir << std::endl;
            return;
        }

        for (int digit = 0; digit < 10; digit++) {
            std::string digit_dir = phase_dir + "/" + std::to_string(digit);
            
            if (!std::filesystem::exists(digit_dir)) {
                std::cerr << "è­¦å‘Š: æ•°å­—ç›®å½•ä¸å­˜åœ¨: " << digit_dir << std::endl;
                continue;
            }

            int count = 0;
            for (const auto& entry : std::filesystem::directory_iterator(digit_dir)) {
                if (entry.is_regular_file() && 
                    (entry.path().extension() == ".png" || 
                     entry.path().extension() == ".jpg" ||
                     entry.path().extension() == ".jpeg")) {
                    image_paths_.push_back(entry.path().string());
                    labels_.push_back(digit);
                    count++;
                }
            }
            std::cout << "æ•°å­— " << digit << ": " << count << " å¼ å›¾ç‰‡" << std::endl;
        }
        
        std::cout << "æ€»å…±åŠ è½½: " << image_paths_.size() << " å¼ å›¾ç‰‡" << std::endl;
    }

    torch::data::Example<> get(size_t index) override {
        if (index >= image_paths_.size()) {
            throw std::out_of_range("ç´¢å¼•è¶…å‡ºèŒƒå›´");
        }

        std::string file_path = image_paths_[index];
        int label = labels_[index];

        // ä½¿ç”¨OpenCVè¯»å–å›¾åƒ
        cv::Mat img = cv::imread(file_path, cv::IMREAD_GRAYSCALE);
        if (img.empty()) {
            std::cerr << "é”™è¯¯: æ— æ³•åŠ è½½å›¾åƒ " << file_path << std::endl;
            // è¿”å›ä¸€ä¸ªéšæœºå›¾åƒä½œä¸ºå ä½ç¬¦
            cv::Mat placeholder = cv::Mat::zeros(128, 128, CV_8UC1);
            cv::randu(placeholder, 0, 255);
            img = placeholder;
        }

        // é¢„å¤„ç†ï¼šè°ƒæ•´å¤§å°ã€å½’ä¸€åŒ–ã€æ ‡å‡†åŒ–
        cv::Mat resized, float_img;
        cv::resize(img, resized, cv::Size(128, 128));
        resized.convertTo(float_img, CV_32F, 1.0 / 255.0);
        float_img = (float_img - 0.5) / 0.5;

        // å°†cv::Matè½¬æ¢ä¸ºtorch::Tensor
        torch::Tensor tensor_image = torch::from_blob(float_img.data, {128, 128, 1}, torch::kFloat32);
        tensor_image = tensor_image.permute({2, 0, 1});
        tensor_image = tensor_image.clone(); // ç¡®ä¿æ•°æ®ç‹¬ç«‹

        torch::Tensor tensor_label = torch::full({1}, label, torch::kLong);

        return {tensor_image, tensor_label};
    }

    torch::optional<size_t> size() const override {
        return image_paths_.size();
    }

private:
    std::vector<std::string> image_paths_;
    std::vector<int64_t> labels_;
};

void train() {
    std::cout << "=== å¼€å§‹æ•°å­—è¯†åˆ«æ¨¡å‹è®­ç»ƒ ===" << std::endl;
    
    // è®¾ç½®è®¾å¤‡
    torch::Device device(torch::kCPU);
    if (torch::cuda::is_available()) {
        std::cout << "ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ" << std::endl;
        device = torch::Device(torch::kCUDA);
    } else {
        std::cout << "ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ" << std::endl;
    }

    // åˆ›å»ºæ¨¡å‹
    auto model = SimpleDigitCNN();
    model->to(device);
    
    // åˆ›å»ºä¼˜åŒ–å™¨
    torch::optim::Adam optimizer(model->parameters(), torch::optim::AdamOptions(0.001));

    // åŠ è½½æ•°æ®é›†
    std::string data_dir = "/home/lzs/Vision_Arena_2025_main/number_data";
    std::cout << "åŠ è½½æ•°æ®ä»: " << data_dir << std::endl;
    
    auto train_dataset = DigitDataset(data_dir, true);
    if (train_dataset.size().value_or(0) == 0) {
        std::cerr << "é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®!" << std::endl;
        return;
    }
    
    auto train_loader = torch::data::make_data_loader(
        train_dataset.map(torch::data::transforms::Stack<>()),
        torch::data::DataLoaderOptions().batch_size(32).workers(2)
    );

    // æŸå¤±å‡½æ•°
    auto criterion = torch::nn::CrossEntropyLoss();

    // è®­ç»ƒå‚æ•°
    size_t num_epochs = 20;
    double best_accuracy = 0.0;

    std::cout << "å¼€å§‹è®­ç»ƒ..." << std::endl;
    
    for (size_t epoch = 0; epoch < num_epochs; epoch++) {
        model->train();
        double running_loss = 0.0;
        int correct_predictions = 0;
        int total_samples = 0;

        for (auto& batch : *train_loader) {
            auto data = batch.data.to(device);
            auto targets = batch.target.squeeze().to(device);

            // å‰å‘ä¼ æ’­
            auto output = model->forward(data);
            auto loss = criterion(output, targets);

            // åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad();
            loss.backward();
            optimizer.step();

            running_loss += loss.item<double>();
            
            // è®¡ç®—å‡†ç¡®ç‡
            auto predictions = output.argmax(1);
            correct_predictions += predictions.eq(targets).sum().item<int>();
            total_samples += targets.size(0);
        }

        double epoch_loss = running_loss / std::distance(train_loader->begin(), train_loader->end());
        double accuracy = 100.0 * correct_predictions / total_samples;
        
        std::cout << "Epoch [" << (epoch + 1) << "/" << num_epochs 
                  << "], Loss: " << epoch_loss 
                  << ", å‡†ç¡®ç‡: " << accuracy << "%" << std::endl;

        // ä¿å­˜æœ€ä½³æ¨¡å‹
        if (accuracy > best_accuracy) {
            best_accuracy = accuracy;
            
            // å…³é”®ä¿®å¤ï¼šä½¿ç”¨TorchScriptä¿å­˜æ¨¡å‹
            model->eval();
            torch::jit::Module traced_model;
            try {
                // åˆ›å»ºç¤ºä¾‹è¾“å…¥ç”¨äºè·Ÿè¸ª
                auto example_input = torch::randn({1, 1, 128, 128}).to(device);
                
                // è·Ÿè¸ªæ¨¡å‹
                traced_model = torch::jit::trace(model, example_input);
                
                // ä¿å­˜ä¸ºTorchScriptæ ¼å¼
                std::string model_path = "/home/lzs/CVengers_challenge/models/digit_model_libtorch.pt";
                traced_model.save(model_path);
                
                std::cout << "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹! å‡†ç¡®ç‡: " << accuracy << "%" << std::endl;
                std::cout << "æ¨¡å‹ä¿å­˜ä¸º: " << model_path << std::endl;
                
            } catch (const std::exception& e) {
                std::cerr << "âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: " << e.what() << std::endl;
            }
        }
    }

    std::cout << "=== è®­ç»ƒå®Œæˆ ===" << std::endl;
    std::cout << "æœ€ä½³å‡†ç¡®ç‡: " << best_accuracy << "%" << std::endl;
}

int main(int argc, char** argv) {
    std::cout << "æ•°å­—è¯†åˆ«æ¨¡å‹è®­ç»ƒç¨‹åº" << std::endl;
    std::cout << "====================" << std::endl;
    
    try {
        train();
        std::cout << "ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!" << std::endl;
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "âŒ è®­ç»ƒå¤±è´¥: " << e.what() << std::endl;
        return -1;
    }
}
